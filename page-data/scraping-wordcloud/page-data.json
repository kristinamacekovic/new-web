{"componentChunkName":"component---src-templates-blog-post-js","path":"/scraping-wordcloud/","result":{"data":{"site":{"siteMetadata":{"title":"Kristina Macekovic"}},"markdownRemark":{"id":"19599a6c-76b4-5265-b2ee-ddfee1406c5a","excerpt":"Recently I started going through Harvard's CS109 class, which aims to be a practical and broad intro to data science (using python). I'm enjoying it a lot, and…","html":"<p>Recently I started going through Harvard's <a href=\"http://cs109.github.io/2015/\">CS109 class</a>, which aims to be a practical and broad intro to data science (using python). I'm enjoying it a lot, and it has definitely given me a push to do something with python (finally!).</p>\n<p>A few months ago, I was intrigued by the beautiful SQL lessons at <a href=\"https://selectstarsql.com\">SELECT * SQL</a>—mainly because of the excellent content, but also because of the intriguing data set. The data set deals with last statements of prisoners on death row. It is definitely a controversial topic, but I think an interesting one that can only spark productive discussion. What is really interesting is that such data <em>exists</em> and is <em>publicly accessible.</em></p>\n<p>For the little project, I decided to scrape the data and do some type of short analysis that could be impactful. I ended up doing a word cloud of the statements (inspiration was <a href=\"http://www.goodbyewarden.com/\">Goodbye, Warden</a>, data is <a href=\"https://www.tdcj.texas.gov/death_row/dr_executed_offenders.html\">here</a> and is the same as for SELECT * SQL). So, lets start.</p>\n<h1>The Process</h1>\n<p>Import the relevant modules.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">\t<span class=\"token comment\"># module for http requests</span>\n\t<span class=\"token keyword\">import</span> requests\n\t<span class=\"token comment\"># module for handling markup objects</span>\n\t<span class=\"token keyword\">from</span> bs4 <span class=\"token keyword\">import</span> BeautifulSoup\n\t<span class=\"token comment\"># visualization module</span>\n\t<span class=\"token keyword\">import</span> matplotlib\n\t<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n\t<span class=\"token comment\"># print out graphics in the document</span>\n\t<span class=\"token operator\">%</span>matplotlib inline\n\t<span class=\"token comment\"># module that implements word clouds</span>\n\t<span class=\"token keyword\">from</span> wordcloud <span class=\"token keyword\">import</span> WordCloud</code></pre></div>\n<p>Get the site with the links to all the prisoner information. To get a manageable version, apply BeautifulSoup to the original results. The prettify function can be used to get a more human-readable version of the text.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">\tmain_pg_txt <span class=\"token operator\">=</span> requests<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">\"https://www.tdcj.texas.gov/death_row/dr_executed_offenders.html\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>text\n\t<span class=\"token comment\"># main_pg_txt</span>\n\tmain_pg_html <span class=\"token operator\">=</span> BeautifulSoup<span class=\"token punctuation\">(</span>main_pg_txt<span class=\"token punctuation\">)</span>\n\t<span class=\"token comment\"># main_pg_html.prettify()</span>\n\t<span class=\"token comment\"># main_pg_html</span></code></pre></div>\n<p>Now it's time to figure out how to access the last statements. Here the crucial tools is the dev tools in the browser (element inspector in particular). I was expecting the \"Last Statement\" to have some type of class or id, but unfortunately it didn't have, so I had to find a common structure and use that instead.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/45718b260d0250147cd97ebff76e9426/07a9c/Screenshot2019-02-01at21-d6c00a7a-fa05-474c-89d6-56a21e509766.49.24.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 55.69620253164557%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAACbUlEQVR42o3PS09TURSG4fMziC1Uclp6oaUttJX29A4K4oD4H4wTB4516sREB4aJDhyowUQkgYFCMNwkUYOmFNRqWwIFLEio5VJ6OQ3avqaHapCRK3my9l7J/rK2EF3eZHF5i4VkmjuPxrh++wn3h2d4F1tnPrZGIpUmtZVhO5vjc2pbmS8kN4kk0orauZYRXd5SusCJunrzHtZL17g1MAgVmVL+gHLxEKjyvyX8qlSoVqscHf3k7sMRrtwYYODxC55NvOfB8GsGxz8wNLnI8NSxkdmPPJ9aZGgyytOJCHPRFeV9pVJTQahd/qjUwwvFEtPzMUZnlxiZjjI6s8j4XJRXb5aYfLvE+NwCL2cjjM1FicROBZ5ct1wuI8sy5bJMqVhga2eP75k9drIHlAqHyMU8B3tZcvu75PayFHL7yKXCv18uyTI1hUKB3d1dMpkMPzIZ1je+sRRf5VN8lS/La6yvb5BaW+NrPE48kSCRTLKysko6nSafz1MsFhXC+Z4+ui/0EQp1EwqFCQRDBIMhfL4AHsmPW/IheQP4/QG8Xj8ej5fOTjdut6R0l+scbrcHSfLhD4QRRFGPze7E4fRgsdnRm0xodXpErR6twoBW1CPW6bTG45nWgFrdhErVSEPDGaWrVE0IZoudTncQr9SF0+nF2uagrc2B2WyjtbXOXKfcrX+7VtuCKLag0+kxGs1Yre0IBr0Jm82Jo92Nrc2JzerAZLJQm59mNLT+QxR16HQGNJpmZcPGRg2CxdWN3dOLJ9iPFLqMFO7H4btIu6eHDqkHh9SrnGssri5aHeFjHSHONutQqxpRqzVKWC3wN41pTLjldd9BAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Screenshot2019 02 01at21 d6c00a7a fa05 474c 89d6 56a21e509766 49 24\"\n        title=\"\"\n        src=\"/static/45718b260d0250147cd97ebff76e9426/f058b/Screenshot2019-02-01at21-d6c00a7a-fa05-474c-89d6-56a21e509766.49.24.png\"\n        srcset=\"/static/45718b260d0250147cd97ebff76e9426/c26ae/Screenshot2019-02-01at21-d6c00a7a-fa05-474c-89d6-56a21e509766.49.24.png 158w,\n/static/45718b260d0250147cd97ebff76e9426/6bdcf/Screenshot2019-02-01at21-d6c00a7a-fa05-474c-89d6-56a21e509766.49.24.png 315w,\n/static/45718b260d0250147cd97ebff76e9426/f058b/Screenshot2019-02-01at21-d6c00a7a-fa05-474c-89d6-56a21e509766.49.24.png 630w,\n/static/45718b260d0250147cd97ebff76e9426/40601/Screenshot2019-02-01at21-d6c00a7a-fa05-474c-89d6-56a21e509766.49.24.png 945w,\n/static/45718b260d0250147cd97ebff76e9426/78612/Screenshot2019-02-01at21-d6c00a7a-fa05-474c-89d6-56a21e509766.49.24.png 1260w,\n/static/45718b260d0250147cd97ebff76e9426/07a9c/Screenshot2019-02-01at21-d6c00a7a-fa05-474c-89d6-56a21e509766.49.24.png 1440w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>Using the bs4's function find_all, we can find all links which contain the wanted text.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">\t<span class=\"token comment\"># find all links with text \"Last Statement\"</span>\n\tlinks <span class=\"token operator\">=</span> main_pg_html<span class=\"token punctuation\">.</span>find_all<span class=\"token punctuation\">(</span><span class=\"token string\">'a'</span><span class=\"token punctuation\">,</span> href<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> text<span class=\"token operator\">=</span><span class=\"token string\">\"Last Statement\"</span><span class=\"token punctuation\">)</span>\n\t<span class=\"token comment\"># len(links)</span>\n\t<span class=\"token comment\"># links</span></code></pre></div>\n<p>Now it's easy to get all the href's inside the link tags. Two of the links were of different extensions compared to the others so I manually changed them. Then I defined the urls I'm going to use as the base url concatenated with the extracted links.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">\t<span class=\"token comment\"># get the urls</span>\n\turls <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>link<span class=\"token punctuation\">[</span><span class=\"token string\">'href'</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> link <span class=\"token keyword\">in</span> links<span class=\"token punctuation\">]</span>\n\t<span class=\"token comment\"># urls</span>\n\turls<span class=\"token punctuation\">[</span><span class=\"token number\">13</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token string\">'dr_info/cardenasrubenlast.html'</span>\n\turls<span class=\"token punctuation\">[</span><span class=\"token number\">14</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token string\">'dr_info/pruettrobertlast.html'</span>\n\t<span class=\"token comment\"># urls</span>\n\twhole_urls <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'https://www.tdcj.texas.gov/death_row/'</span> <span class=\"token operator\">+</span> url <span class=\"token keyword\">for</span> url <span class=\"token keyword\">in</span> urls<span class=\"token punctuation\">]</span>\n\t<span class=\"token comment\"># whole_urls</span></code></pre></div>\n<p>Once again, the structure of the pages with the statements wasn't unified so I had to find a pattern and apply it like this (most of the times, it ended up being the 5th paragraph).</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/46f83bfaac08fe3a1f786972b89a900c/73a2e/Screenshot2019-02-01at22-39dccc7f-f8f4-4a61-a959-9d85a38a3d02.19.58.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 29.746835443037973%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAAsTAAALEwEAmpwYAAABb0lEQVR42lWMSU9aYRhG7x8yFe7wcUcEL9DGmlKNRhJnxDLcGlv5H6ZB7EoSGis/QIa4cuPCqHHYOsB100W7cuOiTXsaoDX4JifveZ7FIzF4v3/Cn188Pvzg5OyUm9trOv4d7U6X25779+0+fpuO3+b7N//ZhLRTP6fSuKTauqLa7Pv+4TFHR/t8rtX59KVBabdJabf/t762KO+1KNcO2Kw22a4dUKmfsdO4oNK4QMp4ReYz75lILbGcW2dhdY25dJZsPs/iqsfiu27OM7/i9fJcOsdsOt9jpfCR1JJHulAk422wnPuAFHEs4pERoo5BPOJg6wKhBglpKromYwgFOTCEKr9AKAGUwBCaMtzLuhZENWPohoVthrCMENKwahFzx3mbnOblq0l000XWbGThIGsOwf8uuu48uSLCKMLGDbtEw1FUVUWEuoPGGLY7RTgxg51IYUSnUJwksv0G5R+D/qyzXuNG4sRGY1i2hWma/AWV/BoMMqnOmAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Screenshot2019 02 01at22 39dccc7f f8f4 4a61 a959 9d85a38a3d02 19 58\"\n        title=\"\"\n        src=\"/static/46f83bfaac08fe3a1f786972b89a900c/f058b/Screenshot2019-02-01at22-39dccc7f-f8f4-4a61-a959-9d85a38a3d02.19.58.png\"\n        srcset=\"/static/46f83bfaac08fe3a1f786972b89a900c/c26ae/Screenshot2019-02-01at22-39dccc7f-f8f4-4a61-a959-9d85a38a3d02.19.58.png 158w,\n/static/46f83bfaac08fe3a1f786972b89a900c/6bdcf/Screenshot2019-02-01at22-39dccc7f-f8f4-4a61-a959-9d85a38a3d02.19.58.png 315w,\n/static/46f83bfaac08fe3a1f786972b89a900c/f058b/Screenshot2019-02-01at22-39dccc7f-f8f4-4a61-a959-9d85a38a3d02.19.58.png 630w,\n/static/46f83bfaac08fe3a1f786972b89a900c/40601/Screenshot2019-02-01at22-39dccc7f-f8f4-4a61-a959-9d85a38a3d02.19.58.png 945w,\n/static/46f83bfaac08fe3a1f786972b89a900c/78612/Screenshot2019-02-01at22-39dccc7f-f8f4-4a61-a959-9d85a38a3d02.19.58.png 1260w,\n/static/46f83bfaac08fe3a1f786972b89a900c/73a2e/Screenshot2019-02-01at22-39dccc7f-f8f4-4a61-a959-9d85a38a3d02.19.58.png 1439w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>I then defined a function which goes through an array of urls, for each url processes it, gets the statement and appends it to an array.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">\t<span class=\"token keyword\">def</span> <span class=\"token function\">get_last_statements</span><span class=\"token punctuation\">(</span>urls<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\t\tstatements <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n\t\t<span class=\"token keyword\">for</span> url <span class=\"token keyword\">in</span> urls<span class=\"token punctuation\">:</span>\n\t\t\tsite <span class=\"token operator\">=</span> requests<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span>url<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>text\n\t\t\thtml <span class=\"token operator\">=</span> BeautifulSoup<span class=\"token punctuation\">(</span>site<span class=\"token punctuation\">)</span>\n\t\t\tps <span class=\"token operator\">=</span> html<span class=\"token punctuation\">.</span>find_all<span class=\"token punctuation\">(</span><span class=\"token string\">'p'</span><span class=\"token punctuation\">)</span>\n\t\t\t<span class=\"token keyword\">if</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>ps<span class=\"token punctuation\">)</span> <span class=\"token operator\">>=</span> <span class=\"token number\">6</span><span class=\"token punctuation\">:</span>\n\t\t\t\tstatement <span class=\"token operator\">=</span> ps<span class=\"token punctuation\">[</span><span class=\"token number\">5</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>getText<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\t\t\tstatements<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>statement<span class=\"token punctuation\">)</span>\n\t\t<span class=\"token keyword\">return</span> statements</code></pre></div>\n<p>Assign the statements array with our array of links.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">\tlast_statements <span class=\"token operator\">=</span> get_last_statements<span class=\"token punctuation\">(</span>whole_urls<span class=\"token punctuation\">)</span>\n\t<span class=\"token comment\"># last_statements</span></code></pre></div>\n<p>Join all the statements into one string separated by blanks:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">\tcombined <span class=\"token operator\">=</span> <span class=\"token string\">\" \"</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>statement <span class=\"token keyword\">for</span> statement <span class=\"token keyword\">in</span> last_statements<span class=\"token punctuation\">)</span>\n\t<span class=\"token comment\"># combined</span></code></pre></div>\n<p>Make a word cloud using the Wordcloud function (from the module of the same name) and save to a png file.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">\twordcloud <span class=\"token operator\">=</span> WordCloud<span class=\"token punctuation\">(</span>max_font_size<span class=\"token operator\">=</span><span class=\"token number\">100</span><span class=\"token punctuation\">,</span> max_words<span class=\"token operator\">=</span><span class=\"token number\">200</span><span class=\"token punctuation\">,</span> background_color<span class=\"token operator\">=</span><span class=\"token string\">\"white\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>generate<span class=\"token punctuation\">(</span>combined<span class=\"token punctuation\">)</span>\n\n\t<span class=\"token comment\"># Display the generated image:</span>\n\tplt<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span>wordcloud<span class=\"token punctuation\">,</span> interpolation<span class=\"token operator\">=</span><span class=\"token string\">'bilinear'</span><span class=\"token punctuation\">)</span>\n\tplt<span class=\"token punctuation\">.</span>axis<span class=\"token punctuation\">(</span><span class=\"token string\">\"off\"</span><span class=\"token punctuation\">)</span>\n\tplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\t<span class=\"token comment\"># save to png file</span>\n\twordcloud<span class=\"token punctuation\">.</span>to_file<span class=\"token punctuation\">(</span><span class=\"token string\">'last_statements.png'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h1>The Result</h1>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 400px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/af2bf8782a2c76e4b7602b0ce5cc8704/e17e5/last_statements-fefe8fdd-9376-4547-af05-534c1fbf37b7.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 50%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAIAAAA7N+mxAAAACXBIWXMAAAsTAAALEwEAmpwYAAACDUlEQVR42gXBW2+aUAAAYH77Xpdsb8v20qzNsjTtZtJldWmtSLU1IlgQuQoHOHCO54Icrs5e9rDvk5KQhgikReJwc8t8vCu3GYwhRX1KjiDqbNY0NiYB5T5l25KiA17tT93qT/PaS4X4q5HFppItca/wq21jz9iNVk7UcqKL8S29cApvlkAVZ2u6swpiMGjXF5tiyEouhSZWn4z4zQpqJ27DlVD0aqLupytuWfVUF3LUBABzx82jLdH1FMAcdCNfTFFRSXnMXDuL8x0VAtDy0U+hwBaFSpTIUXTtBrMkfcJES5G9IyHEvIVRM1qzu5BkUhLSOKXy2JyONqjnLgesE1lbWJhNQarEMCgyeojXONNTjJoCddQRQ69U8L6RgIc3Zvo4c79/kQ//Durk4e5KCba5uQYgJ4YWe4Y3H84o5bimOiIG37rVeVIug4xJou5dRl0v//ltpi7B4EReL70fX+XJr8V4sJjfWp/fDc4+/JZlzX/zVZRkLY3aRSiWDsBS2u7Ddr+YOOefbiFmlyfKzcDUVsH1QD19P+QVOfs4nN8bkKXomPJjvH+xN+LCr2QuegmUPKzxw9wYyUpgQseMNqtR9+ohbOWxFhJiWdn4Wk8ZQkcARLTAjw/4xq8t0jdS3tRr5gUd8PskyElWiedXu2nN+jnsnh0vjAEsIRG8Q+ULSWoalihvEGn74nD4Dz2m/lgksNf7AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Last Statements Word Cloud\"\n        title=\"\"\n        src=\"/static/af2bf8782a2c76e4b7602b0ce5cc8704/e17e5/last_statements-fefe8fdd-9376-4547-af05-534c1fbf37b7.png\"\n        srcset=\"/static/af2bf8782a2c76e4b7602b0ce5cc8704/c26ae/last_statements-fefe8fdd-9376-4547-af05-534c1fbf37b7.png 158w,\n/static/af2bf8782a2c76e4b7602b0ce5cc8704/6bdcf/last_statements-fefe8fdd-9376-4547-af05-534c1fbf37b7.png 315w,\n/static/af2bf8782a2c76e4b7602b0ce5cc8704/e17e5/last_statements-fefe8fdd-9376-4547-af05-534c1fbf37b7.png 400w\"\n        sizes=\"(max-width: 400px) 100vw, 400px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<h1>Summary</h1>\n<p>This was a very short exercise in python and web scraping. Definitely, a lot more can be done and a more rigorous approach can be taken. For now it was a good start with immediate results, and maybe some day I'll get back to the data in the future with more ideas. The general approach was:</p>\n<ol>\n<li>Starting point: an origin site with a bunch of links</li>\n<li>Find a way to get all the urls to the separate sites (use dev tools inspector)</li>\n<li>Get all the urls and store them in an array</li>\n<li>Investigate again with element inspector how to get a particular statement from separate site</li>\n<li>Define a function that for each url, grabs a particular statement and stores it in an array</li>\n<li>Combine all the statements into a single string and input it into the wordcloud function</li>\n</ol>","frontmatter":{"title":"Scraping the web and making wordclouds with Python","date":"February 01, 2019","description":null}},"previous":{"fields":{"slug":"/what-i-learn-from-diana/"},"frontmatter":{"title":"What I Learned from Diana"}},"next":{"fields":{"slug":"/design-thinking-notes/"},"frontmatter":{"title":"Notes on Design Thinking"}}},"pageContext":{"id":"19599a6c-76b4-5265-b2ee-ddfee1406c5a","previousPostId":"7e9213c4-063e-5f86-ad25-0298254d52cf","nextPostId":"852a4768-121f-55f3-b03d-eb48eb79369f"}},"staticQueryHashes":["2841359383","617174473"],"slicesMap":{}}